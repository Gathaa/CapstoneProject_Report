% ============================================
% FILE: notation.tex  (concise, ~1 page)
% ============================================

\chapter*{List of Notations}
\addcontentsline{toc}{chapter}{List of Notations}
\thispagestyle{plain}

\begin{longtable}{p{0.22\textwidth} p{0.72\textwidth}}
\toprule
\textbf{Notation} & \textbf{Description} \\
\midrule
\endfirsthead
\toprule
\textbf{Notation} & \textbf{Description} \\
\midrule
\endhead
\bottomrule
\endlastfoot

% ------------ Core sets & items ------------
$\mathcal{D}$          & Corpus / collection of texts (documents). \\
$D$                    & Corpus size (number of documents in $\mathcal{D}$). \\
$d \in \mathcal{D}$    & A single document (text instance). \\
$|d|$                  & Length of document $d$ (e.g., tokens). \\
$\overline{|d|}$       & Average document length across the corpus. \\
$\mathcal{Q}$          & Set of queries (inputs to retrieval/prompting). \\
$q \in \mathcal{Q}$    & A single query. \\
$\mathcal{V}$          & Vocabulary (set of terms). \\
$t \in \mathcal{V}$    & A single term/token. \\

% ------------ Labels & predictions ----------
$\mathcal{C}$          & Set of emotion labels/classes (e.g., 6 / 15 / 27). \\
$y \in \mathcal{C}$    & Ground-truth label. \\
$\hat{y} \in \mathcal{C}$ & Predicted label. \\

% ------------ N-shot & stopping -------------
$N$                    & Number of in-context examples (“N-shot” context size). \\
$N^\star$              & Selected context size after plateau detection. \\
$\varepsilon$          & Plateau tolerance for successive changes across $N$. \\
$p$                    & Plateau patience (consecutive checks before stop). \\

% ------------ Term stats (lexical) ----------
$f(t,d)$               & Term frequency of $t$ in $d$. \\
$\mathrm{df}(t)$       & Document frequency: number of documents containing $t$. \\
$N_{\text{docs}}$      & Total number of documents (alias for $D$ in freq/weighting). \\
$\mathrm{idf}(t)$      & Inverse-document-frequency attribute tied to $t$ (depends on $N_{\text{docs}}$ and $\mathrm{df}(t)$). \\
$k_1$                  & TF saturation attribute in lexical scaling. \\
$b$                    & Length-normalization attribute using $|d|$ and $\overline{|d|}$. \\

% ------------ Embeddings & similarity -------
$\vec{e}(x)\in\mathbb{R}^{m}$ & Dense embedding of text $x$ in $m$ dimensions. \\
$\vec{u},\vec{v}\in\mathbb{R}^{m}$ & Generic embedding vectors. \\
$\vec{u}\cdot \vec{v}$  & Dot product between vectors $\vec{u}$ and $\vec{v}$. \\
$\|\vec{u}\|$           & Vector norm (e.g., Euclidean). \\
$\cos(\vec{u},\vec{v})$ & Cosine-similarity attribute from dot product and norms. \\

% ------------ Fusion / interpolation --------
$\lambda$               & Interpolation weight for combining heterogeneous scores. \\
$S_{\text{lex}}(d,q)$   & Generic lexical-score attribute for $(d,q)$. \\
$S_{\text{sem}}(d,q)$   & Generic semantic-score attribute for $(d,q)$. \\
$S_{\text{fused}}(d,q)$ & Generic fused-score attribute using $\lambda$. \\

% ------------ Probabilities -----------------
$P(y\,|\,x)$            & Model-estimated probability of label $y$ for input $x$. \\
$\sigma(\cdot)$         & Softmax function mapping logits to a probability simplex. \\
\end{longtable}
% ============================================      